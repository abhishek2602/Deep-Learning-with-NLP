{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearRegression_Tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishek2602/Deep-Learning-with-NLP/blob/master/LinearRegression_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QP5bX0X262U8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building a Linear Regression Model"
      ]
    },
    {
      "metadata": {
        "id": "5tsybrCL55n1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0EsTlwno7Dhq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1: Collect Data"
      ]
    },
    {
      "metadata": {
        "id": "XJQJYBO97CgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "3da36ced-7897-40ab-bc6f-9ee09fb478fb"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib.learn import datasets\n",
        "\n",
        "boston = datasets.load_dataset('boston')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-938abce5ef04>:3: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py:80: load_boston (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use scikits.learn.datasets.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:129: load_csv_with_header (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.data instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-y3maZ2o7bzk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 1a: Feature and Target"
      ]
    },
    {
      "metadata": {
        "id": "Agt-OizF7VVS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Input features\n",
        "features = np.array(boston.data)\n",
        "\n",
        "# Actual Output\n",
        "prices = np.array(boston.target)\n",
        "prices = np.reshape(prices, [-1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ByvJJtn7zDQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building the Graph"
      ]
    },
    {
      "metadata": {
        "id": "f9XxwVD97vWc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Input features\n",
        "x = tf.placeholder(shape = [None, 13], dtype = tf.float32, name = 'x-input')\n",
        "\n",
        "# Actual Output\n",
        "y_ = tf.placeholder(shape = [None, 1], dtype = tf.float32, name = 'y-input')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "soEpVezx8L6W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Normalize Data\n",
        "x_n = tf.nn.l2_normalize(x, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4dVl1lkf8UZe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "587d7551-b067-41a8-9151-312d7640409e"
      },
      "cell_type": "code",
      "source": [
        "# Define Weights and Bias\n",
        "W = tf.Variable(tf.zeros(shape = [13, 1]), name = 'Weights')\n",
        "b = tf.Variable(tf.zeros(shape = [1]), name = 'Bias')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K7PrhGtR8jqr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Prediction - Make sure ro use normalized input features\n",
        "y = tf.add(tf.matmul(x_n, W), b, name = 'output')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KVWqYBHn8zkp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss (Cost) Function\n",
        "loss = tf.reduce_mean(tf.square(y - y_), name = 'Loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7D6Hus7x89e2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Gradient Descent Optimizer to minimum loss\n",
        "train_op = tf.train.GradientDescentOptimizer(0.03).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FQPYaLTv9LOQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Executing the Graph"
      ]
    },
    {
      "metadata": {
        "id": "jKekpePh9KOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6cffd9c0-8777-485f-de4d-fe7fbf833ec7"
      },
      "cell_type": "code",
      "source": [
        "#Lets start graph Execution\n",
        "with tf.Session() as sess:\n",
        "    # variables need to be initialized before we can use them\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    #how many times data need to be shown to model\n",
        "    training_epochs = 1000  \n",
        "    \n",
        "    for epoch in range(training_epochs):\n",
        "        \n",
        "        #Calculate train_op and loss\n",
        "        train_model, train_loss = sess.run([train_op,loss],feed_dict={x:features, y_:prices})\n",
        "        \n",
        "        if epoch % 100 == 0:\n",
        "            print ('Training loss at step: ', epoch, ' is ', train_loss)\n",
        "           "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss at step:  0  is  592.1469\n",
            "Training loss at step:  100  is  72.251595\n",
            "Training loss at step:  200  is  67.80703\n",
            "Training loss at step:  300  is  65.681366\n",
            "Training loss at step:  400  is  64.617775\n",
            "Training loss at step:  500  is  64.042\n",
            "Training loss at step:  600  is  63.69156\n",
            "Training loss at step:  700  is  63.44648\n",
            "Training loss at step:  800  is  63.251854\n",
            "Training loss at step:  900  is  63.082523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nvhAtXLY-PAW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Summary is a Tensorflow op that creates protocol buffer containing sumarised data\n",
        "\n",
        "training_loss = tf.summary.scalar('train_loss', loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P7mrY7nN-t_j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log_dir = 'Desktop/MasterFileDS/UpX/Deep_Learing_with_NLP/Linear_Regression_Tensorflow/v1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CvlAdokf_Glw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "2d055b25-2458-45cb-8912-c8f946cfe24f"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    training_epochs = 1000\n",
        "    #Logging and Saving graph\n",
        "    saver = tf.train.Saver()\n",
        "    writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())\n",
        "    #a python class that writes data to disk for Tensorboard\n",
        "    for epoch in range(training_epochs):\n",
        "        train_model, train_loss, loss_log = sess.run([train_op,loss,training_loss],feed_dict={x:features, y_:prices})\n",
        "        writer.add_summary(loss_log, epoch)\n",
        "        if epoch % 100 == 0:\n",
        "            print ('Training loss at step: ', epoch, 'is', train_loss)\n",
        "            print ('Log loss at step:', epoch, 'is', loss_log)\n",
        "    saver.save(sess,log_dir + '/' + 'boston.ckpt')\n",
        "        "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss at step:  0 is 592.1469\n",
            "Log loss at step: 0 is b'\\n\\x11\\n\\ntrain_loss\\x15g\\t\\x14D'\n",
            "Training loss at step:  100 is 72.251595\n",
            "Log loss at step: 100 is b'\\n\\x11\\n\\ntrain_loss\\x15\\xd1\\x80\\x90B'\n",
            "Training loss at step:  200 is 67.80703\n",
            "Log loss at step: 200 is b'\\n\\x11\\n\\ntrain_loss\\x153\\x9d\\x87B'\n",
            "Training loss at step:  300 is 65.681366\n",
            "Log loss at step: 300 is b'\\n\\x11\\n\\ntrain_loss\\x15\\xdc\\\\\\x83B'\n",
            "Training loss at step:  400 is 64.617775\n",
            "Log loss at step: 400 is b'\\n\\x11\\n\\ntrain_loss\\x15M<\\x81B'\n",
            "Training loss at step:  500 is 64.042\n",
            "Log loss at step: 500 is b'\\n\\x11\\n\\ntrain_loss\\x15\\x81\\x15\\x80B'\n",
            "Training loss at step:  600 is 63.69156\n",
            "Log loss at step: 600 is b'\\n\\x11\\n\\ntrain_loss\\x15(\\xc4~B'\n",
            "Training loss at step:  700 is 63.44648\n",
            "Log loss at step: 700 is b'\\n\\x11\\n\\ntrain_loss\\x152\\xc9}B'\n",
            "Training loss at step:  800 is 63.251854\n",
            "Log loss at step: 800 is b'\\n\\x11\\n\\ntrain_loss\\x15\\xe6\\x01}B'\n",
            "Training loss at step:  900 is 63.082523\n",
            "Log loss at step: 900 is b'\\n\\x11\\n\\ntrain_loss\\x15\\x81T|B'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zD2KDYtVAhxU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "1e70bc09-9ceb-461a-dc56-ce5c9d6b618d"
      },
      "cell_type": "code",
      "source": [
        "pip install tensorboardcolab\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BV1HWNnJBph5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "57a4df50-b32b-49cb-a0d4-eb9e1de0f425"
      },
      "cell_type": "code",
      "source": [
        "tbc = TensorBoardColab()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-7b57e92cfae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtbc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTensorBoardColab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'TensorBoardColab' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "RREozXK8Bu2i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}