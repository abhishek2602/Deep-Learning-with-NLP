{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_Prediction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishek2602/Deep-Learning-with-NLP/blob/master/Seq2Seq_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "unQ0_NTC30lk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Models and Tokenizers"
      ]
    },
    {
      "metadata": {
        "id": "pF5Yi1jd30lm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NtXv0k6930lt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Encoder and decoder model"
      ]
    },
    {
      "metadata": {
        "id": "n60gGTPt30lv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "537767b9-6baf-48a8-f7f3-b7788af5e6b1"
      },
      "cell_type": "code",
      "source": [
        "encoder_model = load_model('seq2seq_encoder_eng_hin.hd5')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dmo9eLo830l1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "decoder_model = load_model('seq2seq_decoder_eng_hin.hd5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5l_5E6FL4LX5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load Tokenizer"
      ]
    },
    {
      "metadata": {
        "id": "1syTstV74Jfl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mHWruqW34TE8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_t = pickle.load(open('encoder_tokenizer_eng', 'rb'))\n",
        "decoder_t = pickle.load(open('decoder_tokenizer_hin', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hdm5-UdZ4jXW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define Configuration Parameters"
      ]
    },
    {
      "metadata": {
        "id": "iGs9B7iq4fEE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_encoder_seq_length = 22\n",
        "max_decoder_seq_length = 27"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "INGZLl0w5Ie0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VzXlRsSx5YKj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Function to generate Padded sequences for input string"
      ]
    },
    {
      "metadata": {
        "id": "Lls0F1tb5RvE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cda0Dx6T5k_0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def encode_input(input_str):\n",
        "    \n",
        "    #Convert words to indexes\n",
        "    encoder_seq = encoder_t.texts_to_sequences([input_str])\n",
        "    \n",
        "    #Pad sequences\n",
        "    encoder_input_data = pad_sequences(encoder_seq, maxlen = max_encoder_seq_length, padding = 'post')\n",
        "    \n",
        "    return encoder_input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "99-pezFK6M8Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prediction Function"
      ]
    },
    {
      "metadata": {
        "id": "TBPJHz_b6MT1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JVlbeQb96Xml",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode_sentence(input_str):\n",
        "    \n",
        "    #Convert input string to padded sequence\n",
        "    input_seq = encode_input(input_str)\n",
        "    \n",
        "    #Get the encoder state values\n",
        "    decoder_initial_states_value = encoder_model.predict(input_seq)\n",
        "    \n",
        "    #Build a sequence with '<start>' - starting sequence for Decoder\n",
        "    target_seq = np.zeros((1,1))    \n",
        "    target_seq[0][0] = decoder_t.word_index['<start>']\n",
        "    \n",
        "    #flag to check if prediction should be stopped\n",
        "    stop_loop = False\n",
        "    \n",
        "    #Initialize predicted sentence\n",
        "    predicted_sentence = ''\n",
        "    \n",
        "    #start the loop\n",
        "    while not stop_loop:\n",
        "        \n",
        "        predicted_outputs, h, c = decoder_model.predict([target_seq] + \n",
        "                                                        decoder_initial_states_value)\n",
        "        \n",
        "        #Get the predicted output with highest probability\n",
        "        predicted_output = np.argmax(predicted_outputs[0,-1,:])\n",
        "        \n",
        "        #Get the predicted word from predicter integer\n",
        "        predicted_word = int_to_word_decoder[predicted_output]\n",
        "        \n",
        "        #Check if prediction should stop\n",
        "        if(predicted_word == '<end>' or len(predicted_sentence) > max_decoder_seq_length):\n",
        "            \n",
        "            stop_loop = True\n",
        "            continue\n",
        "                    \n",
        "        #Updated predicted sentence\n",
        "        if (len(predicted_sentence) == 0):\n",
        "            predicted_sentence = predicted_word\n",
        "        else:\n",
        "            predicted_sentence = predicted_sentence + ' ' + predicted_word\n",
        "            \n",
        "        #Update target_seq to be the predicted word index\n",
        "        target_seq[0][0] = predicted_output\n",
        "        \n",
        "        #Update initial states value for decoder\n",
        "        decoder_initial_states_value = [h,c]\n",
        "        \n",
        "    \n",
        "    return predicted_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "duvJfHZg6ZB9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e5f5c47-4a1d-4f25-8c68-1ef5e58c7ae9"
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    print(decode_sentence('I love you'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "मैं उससे प्यार हूँ।\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wrx9TCV86iGt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}